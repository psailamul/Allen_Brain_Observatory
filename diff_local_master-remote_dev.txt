diff --git a/build/lib/db/db_main.py b/build/lib/db/db_main.py
index 17d9e79..446ab96 100644
--- a/build/lib/db/db_main.py
+++ b/build/lib/db/db_main.py
@@ -13,7 +13,7 @@ main_config = Allen_Brain_Observatory_Config()
 class db(object):
     def __init__(self, config):
         self.status_message = False
-        self.db_schema_file = 'db/db_schema.db'
+        self.db_schema_file = 'db/db_schema.txt'
         # Pass config -> this class
         for k, v in config.items():
             setattr(self, k, v)
@@ -216,4 +216,25 @@ if __name__ == '__main__':
         action='store_true',
         help='Recreate your database.')
     args = parser.parse_args()
-    main(**vars(args))
\ No newline at end of file
+    main(**vars(args))
+
+
+
+"""
+
+cur.execute(
+    'INSERT INTO mytable (ip_id, item) VALUES (%s, %s)',
+    (1, 'someentry')
+)
+data = [
+  ('Jane', date(2005, 2, 12)),
+  ('Joe', date(2006, 5, 23)),
+  ('John', date(2010, 10, 3)),
+]
+stmt = "INSERT INTO employees (first_name, hire_date) VALUES (%s, %s)"
+
+cursor.executemany(stmt, data)
+
+INSERT INTO employees (first_name, hire_date)
+VALUES ('Jane', '2005-02-12'), ('Joe', '2006-05-23'), ('John', '2010-10-03')
+"""
\ No newline at end of file
diff --git a/db/createdb_recover.py b/db/createdb_recover.py
deleted file mode 100644
index 7a16638..0000000
--- a/db/createdb_recover.py
+++ /dev/null
@@ -1,172 +0,0 @@
-
-# ##############################################################################################################
-"""
-CREATE TABLE cells (_id bigserial primary key, cell_specimen_id int, session varchar, drifting_gratings boolean, locally_sparse_noise boolean, locally_sparse_noise_four_deg boolean, locally_sparse_noise_eight_deg boolean, natural_movie_one boolean, natural_movie_two boolean, natural_movie_three boolean, natural_scenes boolean, spontaneous boolean, static_gratings boolean, specimen_recording_pointer varchar, traces_loc_pointer varchar, ROImask_loc_pointer varchar, stim_table_loc_pointer varchar)
-
-@@ 9,38 +9,39 @@ ALTER TABLE cells ADD CONSTRAINT unique_cells UNIQUE (cell_specimen_id, session
-ALTER TABLE rf ADD CONSTRAINT unique_rfs UNIQUE (cell_specimen_id , lsn_name , experiment_container_id , found_on , found_off , alpha , number_of_shuffles , on_distance , on_area , on_overlap , on_height , on_center_x , on_center_y , on_width_x , on_width_y , on_rotation , off_distance , off_area , off_overlap, off_height , off_center_x , off_center_y , off_width_x , off_width_y , off_rotation )
-
-"""
-# ##############################################################################################################
-from allensdk.core.brain_observatory_cache import BrainObservatoryCache
-import matplotlib.pyplot as plt
-from config import Allen_Brain_Observatory_Config
-from tqdm import tqdm
-import pandas as pd
-import numpy as np
-from db_main import db, add_cell_data, initialize_database, get_performance
-
-from helper_funcs import *
-import time 
-import os 
-import sys
-sys.stdout.flush()
-from tqdm import tqdm
-main_config=Allen_Brain_Observatory_Config()
-boc = BrainObservatoryCache(manifest_file=main_config.manifest_file)
-output_data_folder = main_config.output_pointer_loc
-
-df = pd.read_csv('all_exps.csv')
-exp_con_ids = np.asarray(df['experiment_container_id'])
-all_cells_RF_info =[]
-DATE_STAMP = time.strftime('%D').replace('/','_')
-
-#psql allenedatabase h 127.0.0.1 d allendatabase
-# Create DB dict and save output_pointers  at main_config.output_pointer_loc
-############################# My take
-def session_filters(main_config,cells_ID_list):
-     """Find cells that present in all sessions"""
-    masterkey = {k:v for k, v in main_config.session.iteritems() if v in cells_ID_list.keys()}
-    reference_session = masterkey[masterkey.keys()[0]]
-    reference_cells = cells_ID_list[reference_session]
-    flist = {} #List of cells that found in all three sessions
-
-def add_None_to_rfdict(Ref_dict, FLAG_ON=False,FLAG_OFF=False):
-    Ref_dict[key]=None
-    return Ref_dict
-
-def get_all_pointers(main_config, cid,sess,stim):
-    sess_type = sess['session_type']
-    if stim in main_config.available_stims:
-        stim_template="%s%s_template.pkl"%(main_config.stimulus_template_loc,stim)
-    else:
-        stim_template=None
-    pointer_list ={
-        'fluorescence_trace':"%s%s_%s_traces.npz"%(main_config.fluorescence_traces_loc,cid,sess_type),
-        'stim_table':"%s%s_%s_%s_table.npz"%(main_config.stim_table_loc,sess['id'],sess_type,stim),
-        'other_recording':"%s%s_related_traces.npz"%(main_config.specimen_recording_loc,sess['id']),
-        'ROImask':"%s%s_%s_ROImask.npz"%(main_config.ROIs_mask_loc,cid,sess_type),
-        'stim_template':stim_template,
-        }
-    return pointer_list
-
-def get_sess_key(main_config, sesstxt):
-    for code,txt in main_config.session.iteritems():
-        if sesstxt == txt :
-            return code
-
-def get_stim_list_boolean(boc, main_config, this_stim, output_dict): 
-    for stim in boc.get_all_stimuli():
-        if stim in main_config.sess_with_number.keys():
-            stim=main_config.sess_with_number[stim]
-            output_dict[stim]=False
-        output_dict[this_stim]=True
-    return output_dict
-
-
-df = pd.read_csv('all_exps.csv')
-exp_con_ids = np.asarray(df['experiment_container_id'])
-all_cells_RF_info =[]
-start = 0
-end =len(exp_con_ids)
-if len(sys.argv) >1:
-    start=int(sys.argv[1])
-    end=int(sys.argv[2])
-idx_range =np.arange(start,end)
-
-Recorded_all_cells={}
-time_everything=time.time()
-RFs_info = load_object(config.RF_info_loc+"all_cells_RF_info_08_30_17.pkl") # ---> list of exp / then dict of cell name
-
-Recorded_cells_list={}
-cells_ID_list={}
-output_data_folder = main_config.output_pointer_loc
-OUTPUT_POINTER_SAVED = False
-
-for idx in tqdm(
-            idx_range,
-            desc="Data from the experiment",
-            total=len(idx_range)):
-    exps=exp_con_ids[idx]
-    print "Start running experiment container ID #%s  index = %g of [%g,%g)"%(exps,idx,start,end)
-    runtime=time.time()
-
-    exp_session = boc.get_ophys_experiments(experiment_container_ids=[exps]) 
-    RFinfo_this_exp =RFs_info[idx]
-
-    # Get common cells
-    for sess in exp_session:
-        sess_code = get_sess_key(main_config,sess['session_type'])
-        tmp=boc.get_ophys_experiment_data(sess['id'])
-        cells_ID_list[sess['session_type']]=tmp.get_cell_specimen_ids()
-    common_cells = session_filters(main_config,cells_ID_list) 
-
-    common_cell_id=[]
-    for cell_specimen_id, session_filter in common_cells.iteritems():
-        if session_filter:
-            common_cell_id.append(cell_specimen_id)
-    ###############################################
-    # get RF and cell DB for each cell
-    for cell_id in common_cell_id:
-        this_cell_rf =RFinfo_this_exp[cell_id]
-        for rf in this_cell_rf:
-            if rf['lsn_name'] in config.pick_main_RF:
-                represent_RF =  rf
-        cell_rf_dict = represent_RF.copy()
-        cell_rf_dict = add_None_to_rfdict(cell_rf_dict, FLAG_ON=cell_rf_dict['found_on'], FLAG_OFF=cell_rf_dict['found_off'])
-        list_of_cell_stim_dicts = []
-        for session in exp_session:
-            data_set= boc.get_ophys_experiment_data(session['id'])
-            for stimulus in data_set.list_stimuli():
-                output_pointer = os.path.join(output_data_folder, '%s_%s_%s.npy' % (cell_id, session['session_type'], stimulus)) 
-                if(OUTPUT_POINTER_SAVED):
-                    all_pointers=get_all_pointers(config=config, cid=cell_id,sess=session, stim=stimulus)
-                    if stimulus in config.session_name_for_RF:
-                        for rf in this_cell_rf:
-                            if rf['lsn_name'] == stimulus:
-                                rf_from_this_stim = rf.copy()
-                        np.savez(
-                          output_pointer,
-                          neural_trace=all_pointers['fluorescence_trace'],
-                          stim_template=all_pointers['stim_template'],
-                          stim_table=all_pointers['stim_table'],
-                          ROImask=all_pointers['ROImask'],
-                          other_recording=all_pointers['other_recording'],
-                          RF_info=rf_from_this_stim)
-                    else:
-                      np.savez(
-                          output_pointer,
-                          neural_trace=all_pointers['fluorescence_trace'],
-                          stim_template=all_pointers['stim_template'],
-                          stim_table=all_pointers['stim_table'],
-                          ROImask=all_pointers['ROImask'],
-                          other_recording=all_pointers['other_recording'])
-            it_stim_dict = {
-                  'cell_specimen_id':cell_id,
-                  'session':session['session_type'],
-                  'cell_output_npy':output_pointer}
-            it_stim_dict=get_stim_list_boolean(
-                                  boc=boc, 
-                                  main_config=main_config, 
-                                  this_stim=stimulus, 
-                                  output_dict=it_stim_dict) 
-            list_of_cell_stim_dicts += [it_stim_dict]
-      Recorded_cells_list[cell_id]={'cell_rf_dict':cell_rf_dict, 
-                                    'list_of_cell_stim_dicts':list_of_cell_stim_dicts}
-      add_cell_data(
-                cell_rf_dict,
-                list_of_cell_stim_dicts)
-tmptime=time.strftime('%D_%H_%M_%S')
-tmptime=tmptime.replace('/','_')
-fname="Recorded_cells_list_for_db_%s.pkl"%tmptime
-save_object(Recorded_cells_list,fname)
\ No newline at end of file
diff --git a/db/db_main_recover.py b/db/db_main_recover.py
deleted file mode 100644
index f3408ff..0000000
--- a/db/db_main_recover.py
+++ /dev/null
@@ -1,219 +0,0 @@
-#!/usr/bin/env python
-import sys
-import sshtunnel
-import argparse
-import psycopg2
-import psycopg2.extras
-import psycopg2.extensions
-import credentials
-from config import Allen_Brain_Observatory_Config
-sshtunnel.DAEMON = True  # Prevent hanging process due to forward thread
-main_config = Allen_Brain_Observatory_Config()
-
-class db(object):
-    def __init__(self, config):
-        self.status_message = False
-        self.db_schema_file = 'db/db_schema.db'
-        # Pass config -> this class
-        for k, v in config.items():
-            setattr(self, k, v)
-
-    def __enter__(self):
-        if main_config.db_ssh_forward:
-            forward = sshtunnel.SSHTunnelForwarder(
-                credentials.machine_credentials()['ssh_address'],
-                ssh_username=credentials.machine_credentials()['username'],
-                ssh_password=credentials.machine_credentials()['password'],
-                remote_bind_address=('127.0.0.1', 5432))
-            forward.start()
-            self.forward = forward
-            self.pgsql_port = forward.local_bind_port
-        else:
-            self.forward = None
-            self.pgsql_port = ''
-        pgsql_string = credentials.postgresql_connection(str(self.pgsql_port))
-        self.pgsql_string = pgsql_string
-        self.conn = psycopg2.connect(**pgsql_string)
-        self.conn.set_isolation_level(
-            psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
-        self.cur = self.conn.cursor(
-            cursor_factory=psycopg2.extras.RealDictCursor)
-        return self
-
-    def __exit__(self, exc_type, exc_value, traceback):
-        if exc_type is not None:
-            print exc_type, exc_value, traceback
-            self.close_db(commit=False)
-        else:
-            self.close_db()
-        if main_config.db_ssh_forward:
-            self.forward.close()
-        return self
-
-    def close_db(self, commit=True):
-        self.conn.commit()
-        self.cur.close()
-        self.conn.close()
-
-    def return_status(
-            self,
-            label,
-            throw_error=False):
-        """
-        General error handling and status of operations.
-        ::
-        label: a string of the SQL operation (e.g. 'INSERT').
-        throw_error: if you'd like to terminate execution if an error.
-        """
-        if label in self.cur.statusmessage:
-            print 'Successful %s.' % label
-        else:
-            if throw_error:
-                raise RuntimeError('%s' % self.cur.statusmessag)
-            else:
-                'Encountered error during %s: %s.' % (
-                    label, self.cur.statusmessage
-                    )
-
-    def recreate_db(self, run=False):
-        """Initialize the DB with db_schema_file."""
-        if run:
-            db_schema = open(self.db_schema_file).read().splitlines()
-            for s in db_schema:
-                t = s.strip()
-                if len(t):
-                    self.cur.execute(t)
-
-    def populate_db_with_cell_stim(self, namedict):
-        """
-        Add cell stim info to the db.
-        ::
-        experiment_name: name of experiment to add
-        parent_experiment: linking a child (e.g. clickme) -> parent (ILSVRC12)
-        """
-        self.cur.executemany(
-            """
-            INSERT INTO cells
-            (cell_specimen_id, session , drifting_gratings , locally_sparse_noise , locally_sparse_noise_four_deg , locally_sparse_noise_eight_deg , natural_movie_one , natural_movie_two , natural_movie_three , natural_scenes , spontaneous , static_gratings , cell_output_npy)
-            VALUES
-            (%(cell_specimen_id)s, %(session)s, %(drifting_gratings)s, %(locally_sparse_noise)s, %(locally_sparse_noise_four_deg)s, %(locally_sparse_noise_eight_deg)s, %(natural_movie_one)s, %(natural_movie_two)s, %(natural_movie_three)s, %(natural_scenes)s, %(spontaneous)s, %(static_gratings)s, %(cell_output_npy)s)
-            """,
-            namedict)
-        if self.status_message:
-            self.return_status('INSERT')
-
-    def populate_db_with_rf(self, namedict):
-        """
-        Add cell RF info to the db.
-        ::
-        experiment_name: name of experiment to add
-        parent_experiment: linking a child (e.g. clickme) -> parent (ILSVRC12)
-        """
-        self.cur.executemany(
-            """
-            INSERT INTO rf
-            (cell_specimen_id , lsn_name , experiment_container_id , found_on , found_off , alpha , number_of_shuffles , on_distance , on_area , on_overlap , on_height , on_center_x , on_center_y , on_width_x , on_width_y , on_rotation , off_distance , off_area , off_overlap, off_height , off_center_x , off_center_y , off_width_x , off_width_y , off_rotation )
-            VALUES
-            (%(cell_specimen_id)s, %(lsn_name)s, %(experiment_container_id)s, %(found_on)s, %(found_off)s, %(alpha)s, %(number_of_shuffles)s, %(on_distance)s, %(on_area)s, %(on_overlap)s, %(on_height)s, %(on_center_x)s, %(on_center_y)s, %(on_width_x)s, %(on_width_y)s, %(on_rotation)s, %(off_distance)s, %(off_area)s, %(off_overlap)s, %(off_height)s, %(off_center_x)s, %(off_center_y)s, %(off_width_x)s, %(off_width_y)s, %(off_rotation)s)
-            """,
-            namedict)
-        if self.status_message:
-            self.return_status('INSERT')
-
-    def select_cells_by_rf_coor(self, namedict):
-        """
-        Select cells by rf coordinates.
-        """
-        self.cur.execute(
-            """
-            SELECT * FROM rf
-            WHERE on_center_x >= %s and on_center_x < %s and on_center_y >= %s and on_center_y < %s
-            """
-            %
-            (namedict['x_min'], namedict['x_max'], namedict['y_min'], namedict['y_max']))
-        if self.status_message:
-            self.return_status('INSERT')
-        return self.cur.fetchall()
-
-def initialize_database():
-    """Initialize the psql database from the schema file."""
-    config = credentials.postgresql_connection()
-    with db(config) as db_conn:
-        db_conn.recreate_db(run=True)
-        db_conn.return_status('CREATE')
-
-
-def get_cells_by_rf(list_of_dicts):
-    """Query cells by their RF centers."""
-    config = credentials.postgresql_connection()
-    queries =[]
-    with db(config) as db_conn:
-        for d in list_of_dicts:
-            queries = [db_conn.select_cells_by_rf_coor(d)]
-    return queries
-
-
-def add_cell_data(
-        cell_rf_dict,
-        list_of_cell_stim_dicts):
-    """Add a cell to the databse.
-
-    Inputs:::
-    cell_rf_dict: dictionary containing cell_id_number and its RF properties.
-    list_of_cell_stim_dicts: a list of dictionaries, each containing the cell's
-        id  a pointer to a data numpy file and a boolean for the stimuli it contains.
-    ------------------------------
-    For a given cell, e.g., cell_1
-
-    cell_rf_dict = {
-        'cell_id': 1,
-        'rf': big
-    }
-    list_of_cell_stim_dicts[
-        {
-            'cell_id': 1,
-            'session': A,
-            'drifting_gratings': True,
-            'ALL OTHER COLUMNS': False,
-            'cell_npy': os.path.join(data_dir, '%s_%s_%s.npy' % (cell_id, session, stimulus))
-        },
-        {
-            'cell_id': 1,
-            'session': B,
-            'drifting_gratings': True,
-            'ALL OTHER COLUMNS': False,
-            'cell_npy': os.path.join(data_dir, '%s_%s_%s.npy' % (cell_id, session, stimulus))
-        }
-    ]    
-    """
-    config = credentials.postgresql_connection()
-    with db(config) as db_conn:
-        db_conn.populate_db_with_rf(cell_rf_dict)
-        db_conn.populate_db_with_cell_stim(list_of_cell_stim_dicts)
-
-
-def get_performance(experiment_name):
-    config = credentials.postgresql_connection()
-    with db(config) as db_conn:
-        perf = db_conn.get_performance(experiment_name=experiment_name)
-    return perf
-
-def main(
-        initialize_db,
-        reset_process=False):
-    if reset_process:
-        reset_in_process()
-    if initialize_db:
-        print 'Initializing database.'
-        initialize_database()
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--initialize",
-        dest="initialize_db",
-        action='store_true',
-        help='Recreate your database.')
-    args = parser.parse_args()
-    main(**vars(args))
\ No newline at end of file
diff --git a/db/db_schema.db b/db/db_schema.db
deleted file mode 100644
index d0aa523..0000000
--- a/db/db_schema.db
+++ /dev/null
@@ -1,12 +0,0 @@
-DROP TABLE IF EXISTS cells
-DROP TABLE IF EXISTS rf
-
-CREATE TABLE cells (_id bigserial primary key, cell_specimen_id int, session varchar, drifting_gratings boolean, locally_sparse_noise boolean, locally_sparse_noise_four_deg boolean, locally_sparse_noise_eight_deg boolean, natural_movie_one boolean, natural_movie_two boolean, natural_movie_three boolean, natural_scenes boolean, spontaneous boolean, static_gratings boolean, cell_output_npy varchar)
-
-CREATE TABLE rf (_id bigserial primary key, cell_specimen_id int, lsn_name varchar, experiment_container_id int, found_on boolean, found_off boolean, alpha float, number_of_shuffles int, on_distance float, on_area float, on_overlap float, on_height float, on_center_x float, on_center_y float, on_width_x float, on_width_y float, on_rotation float, off_distance float, off_area float, off_overlap float, off_height float, off_center_x float, off_center_y float, off_width_x float, off_width_y float, off_rotation float)
-
-ALTER TABLE cells ADD CONSTRAINT unique_cells UNIQUE (cell_specimen_id, session , drifting_gratings , locally_sparse_noise , locally_sparse_noise_four_deg , locally_sparse_noise_eight_deg , natural_movie_one , natural_movie_two , natural_movie_three , natural_scenes , spontaneous , static_gratings , cell_output_npy)
-
-ALTER TABLE rf ADD CONSTRAINT unique_rfs UNIQUE (cell_specimen_id , lsn_name , experiment_container_id , found_on , found_off , alpha , number_of_shuffles , on_distance , on_area , on_overlap , on_height , on_center_x , on_center_y , on_width_x , on_width_y , on_rotation , off_distance , off_area , off_overlap, off_height , off_center_x , off_center_y , off_width_x , off_width_y , off_rotation )
-
-
diff --git a/pachaya_scripts/queries_by_rf.py b/pachaya_scripts/queries_by_rf.py
index dea5f36..5ac6967 100644
--- a/pachaya_scripts/queries_by_rf.py
+++ b/pachaya_scripts/queries_by_rf.py
@@ -132,8 +132,9 @@ class RF_queries_generator():
             if conditions.find(',') == -1 : # No seperator
                 print "Error : unknown condition expression"
             else:
+
                 if FLAG_FIRST:
-                    command_text+= " and"
+                    command_text+=" and"
                 else:
                     FLAG_FIRST = True
                 lo_bound,up_bound = conditions.split(',') 
